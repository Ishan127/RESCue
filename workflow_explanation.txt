RESCue Pipeline Evaluation Workflow
===================================

This document explains the end-to-end workflow when running `python scripts/evaluate.py`.

1. Initialization
-----------------
*   **Dataset Loading**: The script loads the "ReasonSeg_val" dataset from Hugging Face (`Ricky06662/ReasonSeg_val`).
*   **Pipeline Setup**: Use `RESCuePipeline` to initialize:
    *   **Planner**: Connects to the local vLLM server (`Qwen3-VL`) at port 8000.
    *   **Executor**: Connects to the local SAM3 server at port 8001.
    *   **Verifier**: Uses the same vLLM endpoint as the Planner.

2. Sample Processing Loop
-------------------------
For each image in the dataset (subset based on `--fraction`):

### A. Pre-processing
*   The script extracts the raw image, the natural language query (e.g., "the red car"), and the Ground Truth (GT) binary mask.
*   The image is temporarily saved to disk as `temp_eval_{i}.jpg` because the Planner API expects a file path.

### B. Pipeline Execution (`pipeline.run`)

#### Step 1: Planning (LLM)
*   **Input**: Image + User Query.
*   **Action**: The Planner (Qwen3-VL) analyzes the image.
*   **Output**: It generates `N` (default 4) "Hypotheses". Each hypothesis contains:
    *   `noun_phrase`: A specific object to segment (e.g., "front left tire").
    *   `box`: A bounding box `[x1, y1, x2, y2]` for that object.
    *   `reasoning`: Why this object answers the query.
*   The Planner generates these using different "temperature" settings (conservative vs. exploratory) to ensure diversity.

#### Step 2: Execution (SAM3)
*   **Input**: Image (as numpy array) + Bounding Box + Noun Phrase (Prompt).
*   **Action**: The Executor sends this data to the SAM3 server (port 8001).
    *   The image is Base64 encoded.
    *   SAM3 generates a segmentation mask for the prompt.
    *   Handles shape mismatches (converting (3, H, W) to list of masks).
*   **Output**: A binary segmentation mask.

#### Step 3: Verification (LLM)
*   **Input**: Original Image + Generated Mask + Original Query.
*   **Action**: The system creates a "Red Overlay" image where the mask is highlighted.
*   **Prompt**: The Verifier (Qwen3-VL) is shown the overlay and asked: "Does this red region accurately correspond to '{query}'? Give a score 0-100."
*   **Output**: A confidence score (e.g., 95.0).

### C. Selection & Evaluation
*   The pipeline collects all candidates (`H0_M0`, `H1_M0`, etc.).
*   **Selection**: The candidate with the highest Verification Score is chosen as the "Best Mask".
*   **Metric Calculation**:
    *   The script calculates the **IoU (Intersection over Union)** between the "Best Mask" and the "Ground Truth Mask".
    *   `IoU = (Intersection Area) / (Union Area)`.
*   **Logging**: Prints the Score and IoU for each candidate.

3. Aggregation
--------------
*   After processing all samples, the script computes the **Mean IoU** across the entire processed subset.
